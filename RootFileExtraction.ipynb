{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14871053,"sourceType":"datasetVersion","datasetId":9513318},{"sourceId":14871289,"sourceType":"datasetVersion","datasetId":9513381},{"sourceId":14871351,"sourceType":"datasetVersion","datasetId":9513421},{"sourceId":14871442,"sourceType":"datasetVersion","datasetId":9513364}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Kaggle-ready: ROOT slimming (keep only 50 features) + per-dataset output folders\n\n# If uproot/awkward are missing in your image, uncomment:\n# !pip -q install uproot awkward\n\nimport os, glob, json\nfrom pathlib import Path\n\nimport numpy as np\nimport uproot\nimport awkward as ak\n\n# 1) Set your 50 features here (branch names exactly as in the TTree)\nFEATURES50 = [\n    # مثال (replace with your real 50 branch names):\n    # \"MET_pt\", \"MET_phi\", \"Electron_pt\", ...\n]\n\n# 2) Your dataset paths (as you provided)\nDATASET_PATHS = {\n    \"SMS-TChiWZ_ZToLL\": \"/kaggle/input/datasets/katakuricharlotte/sms-tchiwz-ztoll\",\n    \"DYJetsToLL_0J_TuneCP5\": \"/kaggle/input/datasets/g0ldeneagle/dyjetstoll-0j-tunecp5\",\n    \"WJetsToLNu_TuneCP5\": \"/kaggle/input/datasets/prajwalaaryan/wjetstolnu-tunecp5\",\n    \"TTJets_TuneCP5\": \"/kaggle/input/datasets/darkangel411/ttjets-tunecp5\",\n}\n\nOUT_BASE = \"/kaggle/working/derivedroot\"\nMAX_EVENTS = None          # set int (e.g., 2_000_000) to cap for testing\nSTEP_SIZE = 100_000        # chunk size for streaming\nTREE_PREFERRED = [\"Events\", \"tree\", \"ntuple\", \"T\"]  # try in this order\n\nos.makedirs(OUT_BASE, exist_ok=True)\n\ndef _find_root_strings(obj):\n    \"\"\"Recursively yield any strings ending with .root from an arbitrary JSON structure.\"\"\"\n    if isinstance(obj, str):\n        if obj.lower().endswith(\".root\"):\n            yield obj\n    elif isinstance(obj, dict):\n        for v in obj.values():\n            yield from _find_root_strings(v)\n    elif isinstance(obj, (list, tuple)):\n        for it in obj:\n            yield from _find_root_strings(it)\n\ndef collect_root_files(dataset_dir):\n    dataset_dir = str(dataset_dir)\n    # Prefer json indexes (your Inputs show file_index.json_* entries) [page:1]\n    json_paths = glob.glob(os.path.join(dataset_dir, \"**\", \"*file_index.json*\"), recursive=True)\n    roots = set()\n\n    for jp in json_paths:\n        try:\n            with open(jp, \"r\") as f:\n                data = json.load(f)\n            for s in _find_root_strings(data):\n                roots.add(s)\n        except Exception as e:\n            print(f\"[WARN] Could not parse {jp}: {e}\")\n\n    # Fallback: direct .root files inside the dataset directory (if any)\n    if not roots:\n        for rp in glob.glob(os.path.join(dataset_dir, \"**\", \"*.root\"), recursive=True):\n            roots.add(rp)\n\n    return sorted(roots), sorted(json_paths)\n\ndef pick_tree_name(uproot_file):\n    keys = [k.split(\";\")[0] for k in uproot_file.keys()]\n    for cand in TREE_PREFERRED:\n        if cand in keys:\n            return cand\n    # fallback: first TTree\n    for k in keys:\n        try:\n            obj = uproot_file[k]\n            if isinstance(obj, uproot.behaviors.TTree.TTree):\n                return k\n        except Exception:\n            pass\n    raise RuntimeError(f\"No TTree found in file. Keys: {keys[:50]} ...\")\n\ndef to_numpy_dict(ak_arrays, features):\n    out = {}\n    for name in features:\n        if name not in ak_arrays.fields:\n            continue\n        # Expecting flat scalar branches for \"50 features\" -> convert to numpy 1D\n        out[name] = ak.to_numpy(ak_arrays[name])\n    return out\n\ndef write_slim_root(root_files, out_root_path, features, max_events=None, step_size=100_000):\n    if not root_files:\n        raise RuntimeError(\"No ROOT files found (from file_index.json or direct .root scan).\")\n\n    n_written = 0\n    wrote_tree = False\n\n    # uproot.recreate overwrites/creates a ROOT file for output [web:11]\n    with uproot.recreate(out_root_path) as fout:\n        for i, rf in enumerate(root_files):\n            try:\n                with uproot.open(rf) as fin:\n                    tree_name = pick_tree_name(fin)\n                    tree = fin[tree_name]\n\n                    available = set(tree.keys())\n                    keep = [b for b in features if b in available]\n                    missing = [b for b in features if b not in available]\n\n                    if i == 0:\n                        print(f\"[INFO] Using tree '{tree_name}' from first readable file.\")\n                        if missing:\n                            print(f\"[WARN] Missing {len(missing)} branches (will be skipped): {missing[:10]} ...\")\n\n                    if not keep:\n                        print(f\"[WARN] No requested branches found in {rf}; skipping.\")\n                        continue\n\n                    for chunk in tree.iterate(keep, step_size=step_size, library=\"ak\"):\n                        chunk_np = to_numpy_dict(chunk, keep)\n                        if not chunk_np:\n                            continue\n\n                        # Create output tree on first chunk (with numpy dtypes)\n                        if not wrote_tree:\n                            branch_types = {k: v.dtype for k, v in chunk_np.items()}\n                            fout.mktree(\"Events\", branch_types)  # output tree name\n                            wrote_tree = True\n\n                        fout[\"Events\"].extend(chunk_np)\n\n                        n = len(next(iter(chunk_np.values())))\n                        n_written += n\n\n                        if (max_events is not None) and (n_written >= max_events):\n                            print(f\"[INFO] Reached MAX_EVENTS={max_events}; stopping.\")\n                            return n_written\n\n            except Exception as e:\n                print(f\"[WARN] Failed to process {rf}: {e}\")\n\n    return n_written\n\n# --- Run for each dataset ---\nif not FEATURES50 or len(FEATURES50) != 50:\n    print(f\"[ACTION REQUIRED] Please set FEATURES50 with exactly 50 branch names. Current len={len(FEATURES50)}\")\nelse:\n    for ds_name, ds_path in DATASET_PATHS.items():\n        ds_out_dir = os.path.join(OUT_BASE, ds_name)\n        os.makedirs(ds_out_dir, exist_ok=True)\n\n        root_files, json_paths = collect_root_files(ds_path)\n\n        out_root = os.path.join(ds_out_dir, f\"derived_{ds_name}.root\")\n        manifest = {\n            \"dataset\": ds_name,\n            \"dataset_path\": ds_path,\n            \"out_root\": out_root,\n            \"n_features_requested\": len(FEATURES50),\n            \"features_requested\": FEATURES50,\n            \"file_index_json_found\": json_paths,\n            \"root_files_found_count\": len(root_files),\n            \"root_files_found_preview\": root_files[:20],\n            \"max_events\": MAX_EVENTS,\n            \"step_size\": STEP_SIZE,\n        }\n\n        with open(os.path.join(ds_out_dir, \"manifest.json\"), \"w\") as f:\n            json.dump(manifest, f, indent=2)\n\n        print(f\"\\n=== {ds_name} ===\")\n        print(f\"[INFO] root files found: {len(root_files)}\")\n        print(f\"[INFO] writing -> {out_root}\")\n\n        n_written = write_slim_root(\n            root_files=root_files,\n            out_root_path=out_root,\n            features=FEATURES50,\n            max_events=MAX_EVENTS,\n            step_size=STEP_SIZE,\n        )\n\n        print(f\"[DONE] Wrote {n_written} events to {out_root}\")\n        print(f\"[DONE] Folder: {ds_out_dir}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":14878426,"datasetId":9518764,"databundleVersionId":15741241},{"sourceType":"datasetVersion","sourceId":14845168,"datasetId":9468572,"databundleVersionId":15704711}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 02 — SUSY Signal Regions (CMS Derived ROOT: DY/WJets/TT vs SMS‑TChiWZ)\n\nThis notebook continues the previous EDA, focusing on *signal-like* selections.\nWe load CMS-derived ROOT features for DY, WJets, TT (background) and SMS‑TChiWZ_ZToLL (signal), apply baseline + physics cleaning, and define control/signal regions for fast validation plots.\n","metadata":{}},{"cell_type":"markdown","source":"## Quick validation checklist (pass/fail)\n\nBefore moving to training, confirm:\n\n1) Inputs loaded:\n- DY/WJets/TT/SUSY have non-zero rows\n- ROOT tree name is detected (typically `Events`)\n\n2) Cleaning is sensible:\n- Event counts decrease only where expected (outliers/trivial events)\n\n3) Regions are populated:\n- Baseline has enough statistics\n- Signal and control regions are both non-empty\n\n4) Plot sanity:\n- `signal_vs_control_met.jpg` is produced and shows a harder MET tail in the signal region by construction.\n","metadata":{}},{"cell_type":"code","source":"# Cell 1 — Install deps (no XRootD needed)\n!pip -q install \"uproot>=5\" awkward vector rich tqdm pandas pyarrow fastparquet matplotlib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import uproot\nimport pandas as pd\nimport numpy as np\nimport glob\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1) Feature schema\n\nWe use a fixed list of ~50 engineered observables spanning:\n- Object multiplicities (`nMuon`, `nElectron`, `nJet`, `nJet_pt30`)\n- MET (`MET_pt`, `MET_phi`, `MET_sumEt`)\n- Leading muon/electron/jet kinematics (pt/eta/phi for indices 0–3 where applicable)\n- Event summaries (`HT`, `ST`)\n- Dilepton/dijet masses (`M_ll`, `M_jj_01`, `M_jj_12`)\n- Angular variables (`delta_phi_*`, `delta_R_*`)\n- b-tag scores (`Jet_btagDeepB_0/1`)\n- Ratios (`HT_ratio`, `MET_pt_HT_ratio`)\n","metadata":{}},{"cell_type":"code","source":"FEATURES = [\n\"nMuon\",\"nElectron\",\"nJet\",\"MET_pt\",\"MET_phi\",\"MET_sumEt\",\n\"Muon_pt_0\",\"Muon_eta_0\",\"Muon_phi_0\",\n\"Muon_pt_1\",\"Muon_eta_1\",\"Muon_phi_1\",\n\"Electron_pt_0\",\"Electron_eta_0\",\"Electron_phi_0\",\n\"Electron_pt_1\",\"Electron_eta_1\",\"Electron_phi_1\",\n\"Jet_pt_0\",\"Jet_eta_0\",\"Jet_phi_0\",\n\"Jet_pt_1\",\"Jet_eta_1\",\"Jet_phi_1\",\n\"Jet_pt_2\",\"Jet_eta_2\",\"Jet_phi_2\",\n\"Jet_pt_3\",\"Jet_eta_3\",\"Jet_phi_3\",\n\"HT\",\"ST\",\"M_ll\",\"M_jj_01\",\"M_jj_12\",\n\"delta_phi_MET_j0\",\"delta_phi_MET_j1\",\"min_delta_phi_MET_jets\",\n\"delta_R_j0_j1\",\"delta_phi_ll\",\"delta_R_ll\",\n\"Jet_btagDeepB_0\",\"Jet_btagDeepB_1\",\n\"MT_lep_MET\",\"HT_ratio\",\"MET_pt_HT_ratio\",\n\"nJet_pt30\",\"Jet_mass_0\",\"LeadLepton_pt\",\"sum_pt_leptons\"\n]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2) Loading approach (fast + robust)\n\nWe read ROOT files with `uproot` and:\n1. Recursively find the first available TTree in each file (usually `Events`)\n2. Iterate in chunks (`step_size`) to control memory\n3. Convert each batch to pandas and append `label` + `source`\n4. Concatenate into a single dataframe for cleaning + selections\n\nWe cap `max_files` during development; increase it once plots and selections look stable.\n","metadata":{}},{"cell_type":"code","source":"import uproot, pandas as pd, glob, gc\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\ndef stream_folder_to_parquet(\n        folder,\n        out_path,\n        label,\n        source,\n        step_size=50000):\n\n    files = sorted(glob.glob(folder+\"/*.root\"))\n\n    print(f\"\\nStreaming {source} from {len(files)} files\")\n\n    writer = None\n    total = 0\n\n    for i, f in enumerate(files):\n\n        print(f\"File {i+1}/{len(files)}\")\n\n        with uproot.open(f) as file:\n\n            tree = None\n\n            # detect tree automatically\n            for key, obj in file.items(recursive=True):\n                if isinstance(obj, uproot.behaviors.TTree.TTree):\n                    tree = obj\n                    break\n\n            if tree is None:\n                print(\"   No tree → skip\")\n                continue\n\n            print(\"   Tree:\", tree.name)\n\n            for batch in tree.iterate(FEATURES, library=\"pd\", step_size=step_size):\n\n                batch[\"label\"] = label\n                batch[\"source\"] = source\n\n                table = pa.Table.from_pandas(batch)\n\n                if writer is None:\n                    writer = pq.ParquetWriter(out_path, table.schema)\n\n                writer.write_table(table)\n\n                total += len(batch)\n\n                # free memory\n                del batch\n                gc.collect()\n\n    if writer:\n        writer.close()\n\n    print(f\"Saved {total} events → {out_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import uproot, pandas as pd, glob, gc\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\ndef stream_real_to_parquet(folder, out_path, step_size=50000):\n\n    files = sorted(glob.glob(folder+\"/*.root\"))\n    print(f\"\\nStreaming REAL from {len(files)} files\")\n\n    writer = None\n    total = 0\n\n    for i, f in enumerate(files):\n\n        print(f\"File {i+1}/{len(files)}\")\n\n        with uproot.open(f) as file:\n\n            # REAL dataset uses \"Features\"\n            if \"Features\" not in file:\n                print(\"   Features tree missing → skip\")\n                continue\n\n            tree = file[\"Features\"]\n            print(\"   Tree: Features\")\n\n            for batch in tree.iterate(FEATURES, library=\"pd\", step_size=step_size):\n\n                batch[\"label\"] = -1\n                batch[\"source\"] = \"REAL\"\n\n                table = pa.Table.from_pandas(batch)\n\n                if writer is None:\n                    writer = pq.ParquetWriter(out_path, table.schema)\n\n                writer.write_table(table)\n\n                total += len(batch)\n\n                del batch\n                gc.collect()\n\n    if writer:\n        writer.close()\n\n    print(f\"Saved {total} REAL events → {out_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3) Inputs\n\nMC/SUSY (derived features, ROOT):\n- `/kaggle/input/datasets/katakuricharlotte/cms-derivedroot/derivedroot/`\n  - DYJetsToLL_0J_TuneCP5\n  - WJetsToLNu_TuneCP5\n  - TTJets_TuneCP5\n  - SMS-TChiWZ_ZToLL\n\nOptional real-data cross-check:\n- `/kaggle/input/datasets/hiteshrs/cms2016g29-5785/processed_events`\n\nNotes:\n- If REAL loads as “0 files / No data loaded”, we treat it as unavailable and proceed with MC-only training tables.\n","metadata":{}},{"cell_type":"code","source":"base_mc = \"/kaggle/input/datasets/katakuricharlotte/cms-derivedroot/derivedroot\"\nbase_real = \"/kaggle/input/datasets/hiteshrs/cms2016g29-5785/processed_events\"\n\nstream_folder_to_parquet(f\"{base_mc}/DYJetsToLL_0J_TuneCP5\", \"/kaggle/working/dy.parquet\", 0, \"DY\")\nstream_folder_to_parquet(f\"{base_mc}/WJetsToLNu_TuneCP5\", \"/kaggle/working/wjets.parquet\", 0, \"WJets\")\nstream_folder_to_parquet(f\"{base_mc}/TTJets_TuneCP5\", \"/kaggle/working/tt.parquet\", 0, \"TT\")\nstream_folder_to_parquet(f\"{base_mc}/SMS-TChiWZ_ZToLL\", \"/kaggle/working/susy.parquet\", 1, \"SUSY\")\n\n# REAL uses Features tree but autodetection already handles it\nstream_folder_to_parquet(base_real, \"/kaggle/working/real.parquet\", -1, \"REAL\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.concat([\n    pd.read_parquet(\"/kaggle/working/dy.parquet\"),\n    pd.read_parquet(\"/kaggle/working/wjets.parquet\"),\n    pd.read_parquet(\"/kaggle/working/tt.parquet\"),\n    pd.read_parquet(\"/kaggle/working/susy.parquet\"),\n    pd.read_parquet(\"/kaggle/working/real.parquet\"),\n], ignore_index=True)\n\nprint(\"Initial events:\", len(df))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4) Cleaning and selections\n\nCleaning steps:\n- Replace ±inf → NaN, drop NaNs\n- Apply detector-realism bounds (e.g., MET and leading object pt upper caps)\n- Apply eta acceptance (|eta| < 5 for all *_eta_* columns)\n- Remove trivial events (require at least one jet or lepton)\n\nRegion definitions:\n- Baseline: `MET_pt > 50`, `nJet >= 2`, `HT > 200`, `LeadLepton_pt > 20`\n- Signal region: `MET_pt > 200`, `HT > 400`, `nJet >= 3`\n- Control region: `MET_pt < 100`, `HT < 300`\n\nOutputs:\n- Diagnostic counts after each stage\n- A first validation plot comparing MET in control vs signal region (log-y), saved to `/kaggle/working/`.\n","metadata":{}},{"cell_type":"code","source":"df = pd.concat([dy, wj, tt, susy, real], ignore_index=True)\n\ndf_clean = df.copy()\n\nprint(\"Initial events:\", len(df_clean))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ndf_clean.replace([np.inf, -np.inf], np.nan, inplace=True)\ndf_clean.dropna(inplace=True)\n\nprint(\"After NaN removal:\", len(df_clean))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# transverse momenta upper bounds (detector realism)\ndf_clean = df_clean[\n    (df_clean[\"MET_pt\"] < 2000) &\n    (df_clean[\"Jet_pt_0\"] < 3000) &\n    (df_clean[\"Muon_pt_0\"] < 2000) &\n    (df_clean[\"Electron_pt_0\"] < 2000)\n]\n\n# eta detector acceptance\neta_cols = [c for c in df_clean.columns if \"_eta_\" in c]\n\nfor c in eta_cols:\n    df_clean = df_clean[df_clean[c].abs() < 5]\n\nprint(\"After physics cleaning:\", len(df_clean))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_clean = df_clean[\n    (df_clean[\"nJet\"] > 0) |\n    (df_clean[\"nMuon\"] > 0) |\n    (df_clean[\"nElectron\"] > 0)\n]\n\nprint(\"After trivial-event removal:\", len(df_clean))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"baseline = df_clean[\n    (df_clean[\"MET_pt\"] > 50) &\n    (df_clean[\"nJet\"] >= 2) &\n    (df_clean[\"HT\"] > 200) &\n    (df_clean[\"LeadLepton_pt\"] > 20)\n]\n\nprint(\"Baseline events:\", len(baseline))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"signal_region = baseline[\n    (baseline[\"MET_pt\"] > 200) &\n    (baseline[\"HT\"] > 400) &\n    (baseline[\"nJet\"] >= 3)\n]\n\nprint(\"Signal region events:\", len(signal_region))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"control_region = baseline[\n    (baseline[\"MET_pt\"] < 100) &\n    (baseline[\"HT\"] < 300)\n]\n\nprint(\"Control region events:\", len(control_region))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell — Plot styling helper (define once)\n\nimport matplotlib as mpl\n\ndef paper_axes(ax,\n              title=None,\n              grid=True,\n              grid_alpha=0.25,\n              spine_width=1.2,\n              tick_width=1.2,\n              label_size=11,\n              tick_size=10):\n    \"\"\"Lightweight 'paper' style formatting for a Matplotlib axis.\"\"\"\n    if title is not None:\n        ax.set_title(title, fontsize=label_size + 1)\n\n    # Spines\n    for s in ax.spines.values():\n        s.set_linewidth(spine_width)\n\n    # Ticks\n    ax.tick_params(axis=\"both\", which=\"major\", labelsize=tick_size,\n                   width=tick_width, length=5, direction=\"in\")\n    ax.tick_params(axis=\"both\", which=\"minor\",\n                   width=tick_width, length=3, direction=\"in\")\n\n    # Labels (keep whatever text you already set; just size them)\n    ax.xaxis.label.set_size(label_size)\n    ax.yaxis.label.set_size(label_size)\n\n    # Grid\n    if grid:\n        ax.grid(True, which=\"major\", alpha=grid_alpha, linewidth=0.8)\n        ax.grid(True, which=\"minor\", alpha=grid_alpha * 0.6, linewidth=0.5)\n\n    return ax\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(6,4), dpi=120)\n\nax.hist(control_region[\"MET_pt\"], bins=100, histtype=\"step\",\n        linewidth=1.8, density=True, label=\"Control\")\n\nax.hist(signal_region[\"MET_pt\"], bins=100, histtype=\"step\",\n        linewidth=1.8, density=True, label=\"Signal region\")\n\nax.set_yscale(\"log\")\nax.set_xlabel(\"MET_pt [GeV]\")\nax.set_ylabel(\"Normalized events\")\nax.legend()\n\npaper_axes(ax)\nfig.tight_layout()\n\nfig.savefig(\"/kaggle/working/signal_vs_control_met.jpg\", dpi=300)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = baseline[baseline[\"label\"] != -1]\n\nX = train_df.drop(columns=[\"label\",\"source\"])\ny = train_df[\"label\"]\n\nprint(\"Training events:\", len(X))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6) Next step (modeling-ready table)\n\nFor training:\n- Use `baseline` events\n- Exclude REAL rows (`label != -1`)\n- Define `X = features` and `y = label`\n\nThis produces a clean binary classification table (background vs SUSY) ready for a baseline model.\n","metadata":{}}]}